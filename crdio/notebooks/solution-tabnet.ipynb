{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    " #TabNetRegressor()\n",
    "#clf.fit(\n",
    "#  X_train, Y_train,\n",
    "#  eval_set=[(X_valid, y_valid)]\n",
    "#)\n",
    "#preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcolumns = list(test.columns)\n",
    "ycolumns = \"NSP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class Gini(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"gini\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        #print(y_true, np.argmax(y_score, 1))\n",
    "        n_size = np.max(y_true)+1\n",
    "        y_true_ = np.eye(n_size)[y_true]\n",
    "        auc = roc_auc_score(y_true_, y_score, average='macro', multi_class=\"ovr\")\n",
    "        return max(2*auc - 1, 0.)\n",
    "\n",
    "class F1(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "        \n",
    "    def __call__(self, y_true, y_score):\n",
    "        return f1_score(y_true, np.argmax(y_score, 1), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = train[xcolumns].values\n",
    "y = train[ycolumns].values\n",
    "X_test = test[xcolumns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "transformer=QuantileTransformer(n_quantiles=300, output_distribution='normal')\n",
    "X_t = transformer.fit_transform(X)\n",
    "X_test_t = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "epoch 0  | loss: 1.30106 | val_0_f1: 0.53125 | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.95786 | val_0_f1: 0.50825 | val_0_gini: 0.22083 |  0:00:00s\n",
      "epoch 2  | loss: 0.8325  | val_0_f1: 0.43052 | val_0_gini: 0.22036 |  0:00:00s\n",
      "epoch 3  | loss: 0.81245 | val_0_f1: 0.47104 | val_0_gini: 0.27272 |  0:00:01s\n",
      "epoch 4  | loss: 0.74872 | val_0_f1: 0.5282  | val_0_gini: 0.29519 |  0:00:01s\n",
      "epoch 5  | loss: 0.67444 | val_0_f1: 0.56938 | val_0_gini: 0.27906 |  0:00:01s\n",
      "epoch 6  | loss: 0.62339 | val_0_f1: 0.61559 | val_0_gini: 0.34914 |  0:00:01s\n",
      "epoch 7  | loss: 0.56238 | val_0_f1: 0.61952 | val_0_gini: 0.30265 |  0:00:02s\n",
      "epoch 8  | loss: 0.55531 | val_0_f1: 0.62377 | val_0_gini: 0.30021 |  0:00:02s\n",
      "epoch 9  | loss: 0.53973 | val_0_f1: 0.62523 | val_0_gini: 0.35278 |  0:00:02s\n",
      "epoch 10 | loss: 0.50996 | val_0_f1: 0.6102  | val_0_gini: 0.32877 |  0:00:02s\n",
      "epoch 11 | loss: 0.50354 | val_0_f1: 0.62309 | val_0_gini: 0.39261 |  0:00:03s\n",
      "epoch 12 | loss: 0.46929 | val_0_f1: 0.64872 | val_0_gini: 0.50661 |  0:00:03s\n",
      "epoch 13 | loss: 0.49086 | val_0_f1: 0.67037 | val_0_gini: 0.52946 |  0:00:03s\n",
      "epoch 14 | loss: 0.48738 | val_0_f1: 0.68868 | val_0_gini: 0.60429 |  0:00:03s\n",
      "epoch 15 | loss: 0.51073 | val_0_f1: 0.72587 | val_0_gini: 0.64682 |  0:00:04s\n",
      "epoch 16 | loss: 0.47555 | val_0_f1: 0.74173 | val_0_gini: 0.65053 |  0:00:04s\n",
      "epoch 17 | loss: 0.44053 | val_0_f1: 0.76968 | val_0_gini: 0.6481  |  0:00:04s\n",
      "epoch 18 | loss: 0.44731 | val_0_f1: 0.7683  | val_0_gini: 0.60189 |  0:00:04s\n",
      "epoch 19 | loss: 0.41904 | val_0_f1: 0.7511  | val_0_gini: 0.64506 |  0:00:05s\n",
      "epoch 20 | loss: 0.44474 | val_0_f1: 0.75211 | val_0_gini: 0.64689 |  0:00:05s\n",
      "epoch 21 | loss: 0.46445 | val_0_f1: 0.73788 | val_0_gini: 0.62772 |  0:00:05s\n",
      "epoch 22 | loss: 0.44894 | val_0_f1: 0.74177 | val_0_gini: 0.62742 |  0:00:05s\n",
      "epoch 23 | loss: 0.43407 | val_0_f1: 0.75342 | val_0_gini: 0.64899 |  0:00:06s\n",
      "epoch 24 | loss: 0.40063 | val_0_f1: 0.76327 | val_0_gini: 0.66432 |  0:00:06s\n",
      "epoch 25 | loss: 0.42529 | val_0_f1: 0.78229 | val_0_gini: 0.67951 |  0:00:06s\n",
      "epoch 26 | loss: 0.39983 | val_0_f1: 0.78252 | val_0_gini: 0.69564 |  0:00:07s\n",
      "epoch 27 | loss: 0.38706 | val_0_f1: 0.78197 | val_0_gini: 0.67479 |  0:00:07s\n",
      "epoch 28 | loss: 0.38012 | val_0_f1: 0.76785 | val_0_gini: 0.64964 |  0:00:07s\n",
      "epoch 29 | loss: 0.38968 | val_0_f1: 0.76259 | val_0_gini: 0.65304 |  0:00:07s\n",
      "epoch 30 | loss: 0.37229 | val_0_f1: 0.75886 | val_0_gini: 0.66623 |  0:00:08s\n",
      "epoch 31 | loss: 0.36741 | val_0_f1: 0.75245 | val_0_gini: 0.66094 |  0:00:08s\n",
      "epoch 32 | loss: 0.36407 | val_0_f1: 0.76001 | val_0_gini: 0.67423 |  0:00:08s\n",
      "epoch 33 | loss: 0.38822 | val_0_f1: 0.77552 | val_0_gini: 0.62828 |  0:00:08s\n",
      "epoch 34 | loss: 0.34976 | val_0_f1: 0.76593 | val_0_gini: 0.65455 |  0:00:09s\n",
      "epoch 35 | loss: 0.35846 | val_0_f1: 0.77248 | val_0_gini: 0.70388 |  0:00:09s\n",
      "epoch 36 | loss: 0.35094 | val_0_f1: 0.77379 | val_0_gini: 0.71169 |  0:00:09s\n",
      "epoch 37 | loss: 0.35559 | val_0_f1: 0.80315 | val_0_gini: 0.75952 |  0:00:09s\n",
      "epoch 38 | loss: 0.33474 | val_0_f1: 0.77548 | val_0_gini: 0.75388 |  0:00:10s\n",
      "epoch 39 | loss: 0.35064 | val_0_f1: 0.76089 | val_0_gini: 0.73706 |  0:00:10s\n",
      "epoch 40 | loss: 0.32912 | val_0_f1: 0.76085 | val_0_gini: 0.74658 |  0:00:10s\n",
      "epoch 41 | loss: 0.3447  | val_0_f1: 0.76769 | val_0_gini: 0.76058 |  0:00:10s\n",
      "epoch 42 | loss: 0.36068 | val_0_f1: 0.79864 | val_0_gini: 0.76896 |  0:00:11s\n",
      "epoch 43 | loss: 0.3601  | val_0_f1: 0.78594 | val_0_gini: 0.77003 |  0:00:11s\n",
      "epoch 44 | loss: 0.32997 | val_0_f1: 0.78471 | val_0_gini: 0.76728 |  0:00:11s\n",
      "epoch 45 | loss: 0.30618 | val_0_f1: 0.76032 | val_0_gini: 0.76367 |  0:00:11s\n",
      "epoch 46 | loss: 0.34324 | val_0_f1: 0.76571 | val_0_gini: 0.76673 |  0:00:12s\n",
      "epoch 47 | loss: 0.27569 | val_0_f1: 0.762   | val_0_gini: 0.76908 |  0:00:12s\n",
      "epoch 48 | loss: 0.34066 | val_0_f1: 0.75898 | val_0_gini: 0.76813 |  0:00:12s\n",
      "epoch 49 | loss: 0.33309 | val_0_f1: 0.74835 | val_0_gini: 0.75884 |  0:00:13s\n",
      "epoch 50 | loss: 0.33342 | val_0_f1: 0.73921 | val_0_gini: 0.72768 |  0:00:13s\n",
      "epoch 51 | loss: 0.32567 | val_0_f1: 0.74217 | val_0_gini: 0.71058 |  0:00:13s\n",
      "epoch 52 | loss: 0.30904 | val_0_f1: 0.7501  | val_0_gini: 0.70613 |  0:00:13s\n",
      "epoch 53 | loss: 0.27937 | val_0_f1: 0.76311 | val_0_gini: 0.71038 |  0:00:14s\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_0_gini = 0.77003\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 1.26092 | val_0_f1: 0.5242  | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 1.0046  | val_0_f1: 0.49697 | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.91324 | val_0_f1: 0.48053 | val_0_gini: 0.18667 |  0:00:00s\n",
      "epoch 3  | loss: 0.82584 | val_0_f1: 0.36222 | val_0_gini: 0.20334 |  0:00:01s\n",
      "epoch 4  | loss: 0.7963  | val_0_f1: 0.42681 | val_0_gini: 0.323   |  0:00:01s\n",
      "epoch 5  | loss: 0.74886 | val_0_f1: 0.45612 | val_0_gini: 0.44289 |  0:00:01s\n",
      "epoch 6  | loss: 0.64791 | val_0_f1: 0.50366 | val_0_gini: 0.52495 |  0:00:01s\n",
      "epoch 7  | loss: 0.59385 | val_0_f1: 0.50933 | val_0_gini: 0.49876 |  0:00:02s\n",
      "epoch 8  | loss: 0.56101 | val_0_f1: 0.61397 | val_0_gini: 0.55182 |  0:00:02s\n",
      "epoch 9  | loss: 0.53801 | val_0_f1: 0.64876 | val_0_gini: 0.54991 |  0:00:02s\n",
      "epoch 10 | loss: 0.48179 | val_0_f1: 0.6414  | val_0_gini: 0.54391 |  0:00:02s\n",
      "epoch 11 | loss: 0.45716 | val_0_f1: 0.64008 | val_0_gini: 0.61313 |  0:00:03s\n",
      "epoch 12 | loss: 0.52747 | val_0_f1: 0.62862 | val_0_gini: 0.63868 |  0:00:03s\n",
      "epoch 13 | loss: 0.47214 | val_0_f1: 0.63744 | val_0_gini: 0.6152  |  0:00:03s\n",
      "epoch 14 | loss: 0.49226 | val_0_f1: 0.66124 | val_0_gini: 0.6297  |  0:00:03s\n",
      "epoch 15 | loss: 0.40372 | val_0_f1: 0.65225 | val_0_gini: 0.6502  |  0:00:04s\n",
      "epoch 16 | loss: 0.43213 | val_0_f1: 0.64426 | val_0_gini: 0.61505 |  0:00:04s\n",
      "epoch 17 | loss: 0.41888 | val_0_f1: 0.63972 | val_0_gini: 0.62727 |  0:00:04s\n",
      "epoch 18 | loss: 0.45008 | val_0_f1: 0.66575 | val_0_gini: 0.65595 |  0:00:04s\n",
      "epoch 19 | loss: 0.4136  | val_0_f1: 0.67456 | val_0_gini: 0.67246 |  0:00:05s\n",
      "epoch 20 | loss: 0.43229 | val_0_f1: 0.67846 | val_0_gini: 0.676   |  0:00:05s\n",
      "epoch 21 | loss: 0.43362 | val_0_f1: 0.68483 | val_0_gini: 0.6855  |  0:00:05s\n",
      "epoch 22 | loss: 0.3826  | val_0_f1: 0.70837 | val_0_gini: 0.69891 |  0:00:05s\n",
      "epoch 23 | loss: 0.40458 | val_0_f1: 0.72687 | val_0_gini: 0.69637 |  0:00:06s\n",
      "epoch 24 | loss: 0.41757 | val_0_f1: 0.72682 | val_0_gini: 0.69099 |  0:00:06s\n",
      "epoch 25 | loss: 0.36484 | val_0_f1: 0.71814 | val_0_gini: 0.66583 |  0:00:06s\n",
      "epoch 26 | loss: 0.35492 | val_0_f1: 0.72593 | val_0_gini: 0.66086 |  0:00:07s\n",
      "epoch 27 | loss: 0.37781 | val_0_f1: 0.73367 | val_0_gini: 0.67571 |  0:00:07s\n",
      "epoch 28 | loss: 0.3615  | val_0_f1: 0.72365 | val_0_gini: 0.67976 |  0:00:07s\n",
      "epoch 29 | loss: 0.34155 | val_0_f1: 0.74253 | val_0_gini: 0.71485 |  0:00:07s\n",
      "epoch 30 | loss: 0.3439  | val_0_f1: 0.7385  | val_0_gini: 0.71619 |  0:00:08s\n",
      "epoch 31 | loss: 0.3215  | val_0_f1: 0.74217 | val_0_gini: 0.71825 |  0:00:08s\n",
      "epoch 32 | loss: 0.35754 | val_0_f1: 0.75508 | val_0_gini: 0.70803 |  0:00:08s\n",
      "epoch 33 | loss: 0.32784 | val_0_f1: 0.75107 | val_0_gini: 0.70062 |  0:00:08s\n",
      "epoch 34 | loss: 0.3422  | val_0_f1: 0.75229 | val_0_gini: 0.68654 |  0:00:09s\n",
      "epoch 35 | loss: 0.31104 | val_0_f1: 0.76254 | val_0_gini: 0.70798 |  0:00:09s\n",
      "epoch 36 | loss: 0.33463 | val_0_f1: 0.78297 | val_0_gini: 0.73584 |  0:00:09s\n",
      "epoch 37 | loss: 0.30681 | val_0_f1: 0.78036 | val_0_gini: 0.74702 |  0:00:10s\n",
      "epoch 38 | loss: 0.25708 | val_0_f1: 0.76868 | val_0_gini: 0.73829 |  0:00:10s\n",
      "epoch 39 | loss: 0.28613 | val_0_f1: 0.76738 | val_0_gini: 0.73152 |  0:00:10s\n",
      "epoch 40 | loss: 0.29393 | val_0_f1: 0.75472 | val_0_gini: 0.72445 |  0:00:10s\n",
      "epoch 41 | loss: 0.28131 | val_0_f1: 0.76296 | val_0_gini: 0.72919 |  0:00:11s\n",
      "epoch 42 | loss: 0.2717  | val_0_f1: 0.78906 | val_0_gini: 0.74342 |  0:00:11s\n",
      "epoch 43 | loss: 0.29775 | val_0_f1: 0.78606 | val_0_gini: 0.76199 |  0:00:11s\n",
      "epoch 44 | loss: 0.26121 | val_0_f1: 0.78543 | val_0_gini: 0.76185 |  0:00:11s\n",
      "epoch 45 | loss: 0.27206 | val_0_f1: 0.77738 | val_0_gini: 0.74954 |  0:00:12s\n",
      "epoch 46 | loss: 0.27427 | val_0_f1: 0.77303 | val_0_gini: 0.76756 |  0:00:12s\n",
      "epoch 47 | loss: 0.25639 | val_0_f1: 0.7776  | val_0_gini: 0.76838 |  0:00:12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 | loss: 0.27765 | val_0_f1: 0.79155 | val_0_gini: 0.78083 |  0:00:12s\n",
      "epoch 49 | loss: 0.26833 | val_0_f1: 0.80392 | val_0_gini: 0.80518 |  0:00:13s\n",
      "epoch 50 | loss: 0.28506 | val_0_f1: 0.81426 | val_0_gini: 0.8145  |  0:00:13s\n",
      "epoch 51 | loss: 0.27914 | val_0_f1: 0.81481 | val_0_gini: 0.79723 |  0:00:13s\n",
      "epoch 52 | loss: 0.25943 | val_0_f1: 0.81598 | val_0_gini: 0.80352 |  0:00:14s\n",
      "epoch 53 | loss: 0.2334  | val_0_f1: 0.82173 | val_0_gini: 0.8127  |  0:00:14s\n",
      "epoch 54 | loss: 0.21765 | val_0_f1: 0.82004 | val_0_gini: 0.81119 |  0:00:14s\n",
      "epoch 55 | loss: 0.26339 | val_0_f1: 0.82099 | val_0_gini: 0.80171 |  0:00:14s\n",
      "epoch 56 | loss: 0.21394 | val_0_f1: 0.83086 | val_0_gini: 0.78962 |  0:00:15s\n",
      "epoch 57 | loss: 0.24686 | val_0_f1: 0.82951 | val_0_gini: 0.77937 |  0:00:15s\n",
      "epoch 58 | loss: 0.27549 | val_0_f1: 0.8264  | val_0_gini: 0.78827 |  0:00:15s\n",
      "epoch 59 | loss: 0.24103 | val_0_f1: 0.82501 | val_0_gini: 0.80102 |  0:00:15s\n",
      "epoch 60 | loss: 0.22208 | val_0_f1: 0.82846 | val_0_gini: 0.79893 |  0:00:16s\n",
      "\n",
      "Early stopping occured at epoch 60 with best_epoch = 50 and best_val_0_gini = 0.8145\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 1.29149 | val_0_f1: 0.5054  | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.96074 | val_0_f1: 0.48618 | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 2  | loss: 0.84925 | val_0_f1: 0.44109 | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 3  | loss: 0.81504 | val_0_f1: 0.35025 | val_0_gini: 0.0     |  0:00:01s\n",
      "epoch 4  | loss: 0.71789 | val_0_f1: 0.41923 | val_0_gini: 0.20709 |  0:00:01s\n",
      "epoch 5  | loss: 0.63306 | val_0_f1: 0.50966 | val_0_gini: 0.36813 |  0:00:01s\n",
      "epoch 6  | loss: 0.59208 | val_0_f1: 0.51621 | val_0_gini: 0.43739 |  0:00:01s\n",
      "epoch 7  | loss: 0.5572  | val_0_f1: 0.55994 | val_0_gini: 0.42944 |  0:00:02s\n",
      "epoch 8  | loss: 0.5181  | val_0_f1: 0.57545 | val_0_gini: 0.55616 |  0:00:02s\n",
      "epoch 9  | loss: 0.50811 | val_0_f1: 0.62343 | val_0_gini: 0.56779 |  0:00:02s\n",
      "epoch 10 | loss: 0.48666 | val_0_f1: 0.67167 | val_0_gini: 0.62739 |  0:00:02s\n",
      "epoch 11 | loss: 0.45998 | val_0_f1: 0.67652 | val_0_gini: 0.60037 |  0:00:03s\n",
      "epoch 12 | loss: 0.43215 | val_0_f1: 0.68238 | val_0_gini: 0.63295 |  0:00:03s\n",
      "epoch 13 | loss: 0.41891 | val_0_f1: 0.66582 | val_0_gini: 0.63181 |  0:00:03s\n",
      "epoch 14 | loss: 0.39365 | val_0_f1: 0.65813 | val_0_gini: 0.65657 |  0:00:03s\n",
      "epoch 15 | loss: 0.41157 | val_0_f1: 0.66209 | val_0_gini: 0.66762 |  0:00:04s\n",
      "epoch 16 | loss: 0.45045 | val_0_f1: 0.65338 | val_0_gini: 0.66529 |  0:00:04s\n",
      "epoch 17 | loss: 0.40687 | val_0_f1: 0.64229 | val_0_gini: 0.64514 |  0:00:04s\n",
      "epoch 18 | loss: 0.38113 | val_0_f1: 0.62275 | val_0_gini: 0.65139 |  0:00:04s\n",
      "epoch 19 | loss: 0.41041 | val_0_f1: 0.63378 | val_0_gini: 0.63206 |  0:00:05s\n",
      "epoch 20 | loss: 0.35592 | val_0_f1: 0.63071 | val_0_gini: 0.61201 |  0:00:05s\n",
      "epoch 21 | loss: 0.3485  | val_0_f1: 0.67433 | val_0_gini: 0.61068 |  0:00:05s\n",
      "epoch 22 | loss: 0.34212 | val_0_f1: 0.71519 | val_0_gini: 0.67568 |  0:00:05s\n",
      "epoch 23 | loss: 0.32167 | val_0_f1: 0.72363 | val_0_gini: 0.70164 |  0:00:06s\n",
      "epoch 24 | loss: 0.31441 | val_0_f1: 0.70426 | val_0_gini: 0.71756 |  0:00:06s\n",
      "epoch 25 | loss: 0.31697 | val_0_f1: 0.72549 | val_0_gini: 0.73081 |  0:00:06s\n",
      "epoch 26 | loss: 0.31329 | val_0_f1: 0.71247 | val_0_gini: 0.696   |  0:00:06s\n",
      "epoch 27 | loss: 0.3107  | val_0_f1: 0.7124  | val_0_gini: 0.68716 |  0:00:07s\n",
      "epoch 28 | loss: 0.303   | val_0_f1: 0.72054 | val_0_gini: 0.6963  |  0:00:07s\n",
      "epoch 29 | loss: 0.26573 | val_0_f1: 0.71771 | val_0_gini: 0.72171 |  0:00:07s\n",
      "epoch 30 | loss: 0.28057 | val_0_f1: 0.72532 | val_0_gini: 0.7443  |  0:00:07s\n",
      "epoch 31 | loss: 0.27169 | val_0_f1: 0.72106 | val_0_gini: 0.73156 |  0:00:08s\n",
      "epoch 32 | loss: 0.27    | val_0_f1: 0.70189 | val_0_gini: 0.73655 |  0:00:08s\n",
      "epoch 33 | loss: 0.28923 | val_0_f1: 0.69971 | val_0_gini: 0.72966 |  0:00:08s\n",
      "epoch 34 | loss: 0.28395 | val_0_f1: 0.7154  | val_0_gini: 0.7533  |  0:00:08s\n",
      "epoch 35 | loss: 0.26566 | val_0_f1: 0.72723 | val_0_gini: 0.76231 |  0:00:09s\n",
      "epoch 36 | loss: 0.25139 | val_0_f1: 0.72717 | val_0_gini: 0.77918 |  0:00:09s\n",
      "epoch 37 | loss: 0.27682 | val_0_f1: 0.71346 | val_0_gini: 0.76637 |  0:00:09s\n",
      "epoch 38 | loss: 0.2392  | val_0_f1: 0.69183 | val_0_gini: 0.74411 |  0:00:09s\n",
      "epoch 39 | loss: 0.25343 | val_0_f1: 0.68914 | val_0_gini: 0.73039 |  0:00:10s\n",
      "epoch 40 | loss: 0.24952 | val_0_f1: 0.67912 | val_0_gini: 0.71742 |  0:00:10s\n",
      "epoch 41 | loss: 0.25779 | val_0_f1: 0.70967 | val_0_gini: 0.71874 |  0:00:10s\n",
      "epoch 42 | loss: 0.25662 | val_0_f1: 0.75089 | val_0_gini: 0.74997 |  0:00:10s\n",
      "epoch 43 | loss: 0.20486 | val_0_f1: 0.79702 | val_0_gini: 0.78417 |  0:00:10s\n",
      "epoch 44 | loss: 0.24312 | val_0_f1: 0.78375 | val_0_gini: 0.73694 |  0:00:11s\n",
      "epoch 45 | loss: 0.25596 | val_0_f1: 0.75308 | val_0_gini: 0.73221 |  0:00:11s\n",
      "epoch 46 | loss: 0.18327 | val_0_f1: 0.73922 | val_0_gini: 0.71543 |  0:00:11s\n",
      "epoch 47 | loss: 0.24299 | val_0_f1: 0.75229 | val_0_gini: 0.71405 |  0:00:12s\n",
      "epoch 48 | loss: 0.22603 | val_0_f1: 0.76244 | val_0_gini: 0.73167 |  0:00:12s\n",
      "epoch 49 | loss: 0.26422 | val_0_f1: 0.73398 | val_0_gini: 0.72608 |  0:00:12s\n",
      "epoch 50 | loss: 0.23544 | val_0_f1: 0.71741 | val_0_gini: 0.70521 |  0:00:12s\n",
      "epoch 51 | loss: 0.25776 | val_0_f1: 0.71641 | val_0_gini: 0.67712 |  0:00:13s\n",
      "epoch 52 | loss: 0.22553 | val_0_f1: 0.72173 | val_0_gini: 0.68549 |  0:00:13s\n",
      "epoch 53 | loss: 0.24586 | val_0_f1: 0.74673 | val_0_gini: 0.7075  |  0:00:13s\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 43 and best_val_0_gini = 0.78417\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 1.2661  | val_0_f1: 0.49301 | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.96513 | val_0_f1: 0.49028 | val_0_gini: 0.03691 |  0:00:00s\n",
      "epoch 2  | loss: 0.85872 | val_0_f1: 0.47211 | val_0_gini: 0.15252 |  0:00:00s\n",
      "epoch 3  | loss: 0.80174 | val_0_f1: 0.52195 | val_0_gini: 0.25533 |  0:00:01s\n",
      "epoch 4  | loss: 0.7311  | val_0_f1: 0.6009  | val_0_gini: 0.3018  |  0:00:01s\n",
      "epoch 5  | loss: 0.69804 | val_0_f1: 0.64027 | val_0_gini: 0.38528 |  0:00:01s\n",
      "epoch 6  | loss: 0.65918 | val_0_f1: 0.68342 | val_0_gini: 0.43512 |  0:00:01s\n",
      "epoch 7  | loss: 0.61907 | val_0_f1: 0.69401 | val_0_gini: 0.49388 |  0:00:02s\n",
      "epoch 8  | loss: 0.6065  | val_0_f1: 0.7216  | val_0_gini: 0.54977 |  0:00:02s\n",
      "epoch 9  | loss: 0.54095 | val_0_f1: 0.69208 | val_0_gini: 0.54169 |  0:00:02s\n",
      "epoch 10 | loss: 0.5199  | val_0_f1: 0.65902 | val_0_gini: 0.51174 |  0:00:02s\n",
      "epoch 11 | loss: 0.49394 | val_0_f1: 0.68206 | val_0_gini: 0.53931 |  0:00:03s\n",
      "epoch 12 | loss: 0.471   | val_0_f1: 0.70145 | val_0_gini: 0.56369 |  0:00:03s\n",
      "epoch 13 | loss: 0.43851 | val_0_f1: 0.69906 | val_0_gini: 0.54969 |  0:00:03s\n",
      "epoch 14 | loss: 0.44586 | val_0_f1: 0.70676 | val_0_gini: 0.56023 |  0:00:03s\n",
      "epoch 15 | loss: 0.39577 | val_0_f1: 0.70664 | val_0_gini: 0.53347 |  0:00:04s\n",
      "epoch 16 | loss: 0.42784 | val_0_f1: 0.71721 | val_0_gini: 0.58166 |  0:00:04s\n",
      "epoch 17 | loss: 0.4175  | val_0_f1: 0.72051 | val_0_gini: 0.63502 |  0:00:04s\n",
      "epoch 18 | loss: 0.41441 | val_0_f1: 0.71756 | val_0_gini: 0.62614 |  0:00:04s\n",
      "epoch 19 | loss: 0.39162 | val_0_f1: 0.72399 | val_0_gini: 0.6493  |  0:00:05s\n",
      "epoch 20 | loss: 0.37407 | val_0_f1: 0.73642 | val_0_gini: 0.70123 |  0:00:05s\n",
      "epoch 21 | loss: 0.3842  | val_0_f1: 0.713   | val_0_gini: 0.72526 |  0:00:05s\n",
      "epoch 22 | loss: 0.38729 | val_0_f1: 0.74929 | val_0_gini: 0.74417 |  0:00:05s\n",
      "epoch 23 | loss: 0.35829 | val_0_f1: 0.76662 | val_0_gini: 0.7789  |  0:00:06s\n",
      "epoch 24 | loss: 0.32985 | val_0_f1: 0.79647 | val_0_gini: 0.82467 |  0:00:06s\n",
      "epoch 25 | loss: 0.37953 | val_0_f1: 0.77489 | val_0_gini: 0.83924 |  0:00:06s\n",
      "epoch 26 | loss: 0.32219 | val_0_f1: 0.74941 | val_0_gini: 0.83766 |  0:00:07s\n",
      "epoch 27 | loss: 0.31189 | val_0_f1: 0.72548 | val_0_gini: 0.83126 |  0:00:07s\n",
      "epoch 28 | loss: 0.334   | val_0_f1: 0.70667 | val_0_gini: 0.81574 |  0:00:07s\n",
      "epoch 29 | loss: 0.37237 | val_0_f1: 0.72509 | val_0_gini: 0.78242 |  0:00:07s\n",
      "epoch 30 | loss: 0.33642 | val_0_f1: 0.73585 | val_0_gini: 0.77681 |  0:00:08s\n",
      "epoch 31 | loss: 0.30395 | val_0_f1: 0.76347 | val_0_gini: 0.79592 |  0:00:08s\n",
      "epoch 32 | loss: 0.33205 | val_0_f1: 0.77894 | val_0_gini: 0.7956  |  0:00:08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 | loss: 0.30323 | val_0_f1: 0.77368 | val_0_gini: 0.81073 |  0:00:08s\n",
      "epoch 34 | loss: 0.2844  | val_0_f1: 0.77311 | val_0_gini: 0.81181 |  0:00:09s\n",
      "epoch 35 | loss: 0.30874 | val_0_f1: 0.77056 | val_0_gini: 0.80854 |  0:00:09s\n",
      "\n",
      "Early stopping occured at epoch 35 with best_epoch = 25 and best_val_0_gini = 0.83924\n",
      "Best weights from best epoch are automatically used!\n",
      "Device used : cpu\n",
      "epoch 0  | loss: 1.23754 | val_0_f1: 0.50728 | val_0_gini: 0.0     |  0:00:00s\n",
      "epoch 1  | loss: 0.97797 | val_0_f1: 0.42361 | val_0_gini: 0.11104 |  0:00:00s\n",
      "epoch 2  | loss: 0.90007 | val_0_f1: 0.39364 | val_0_gini: 0.09773 |  0:00:00s\n",
      "epoch 3  | loss: 0.82504 | val_0_f1: 0.44272 | val_0_gini: 0.1764  |  0:00:00s\n",
      "epoch 4  | loss: 0.76762 | val_0_f1: 0.5458  | val_0_gini: 0.31317 |  0:00:01s\n",
      "epoch 5  | loss: 0.74242 | val_0_f1: 0.6314  | val_0_gini: 0.36599 |  0:00:01s\n",
      "epoch 6  | loss: 0.69633 | val_0_f1: 0.6527  | val_0_gini: 0.44073 |  0:00:01s\n",
      "epoch 7  | loss: 0.68723 | val_0_f1: 0.67319 | val_0_gini: 0.46809 |  0:00:01s\n",
      "epoch 8  | loss: 0.62362 | val_0_f1: 0.65445 | val_0_gini: 0.40996 |  0:00:02s\n",
      "epoch 9  | loss: 0.61178 | val_0_f1: 0.64765 | val_0_gini: 0.37769 |  0:00:02s\n",
      "epoch 10 | loss: 0.57017 | val_0_f1: 0.62824 | val_0_gini: 0.38484 |  0:00:02s\n",
      "epoch 11 | loss: 0.54484 | val_0_f1: 0.62688 | val_0_gini: 0.43616 |  0:00:02s\n",
      "epoch 12 | loss: 0.5278  | val_0_f1: 0.61404 | val_0_gini: 0.42207 |  0:00:03s\n",
      "epoch 13 | loss: 0.49377 | val_0_f1: 0.62721 | val_0_gini: 0.5242  |  0:00:03s\n",
      "epoch 14 | loss: 0.46707 | val_0_f1: 0.64071 | val_0_gini: 0.62315 |  0:00:03s\n",
      "epoch 15 | loss: 0.47945 | val_0_f1: 0.65636 | val_0_gini: 0.66105 |  0:00:04s\n",
      "epoch 16 | loss: 0.46921 | val_0_f1: 0.63764 | val_0_gini: 0.67868 |  0:00:04s\n",
      "epoch 17 | loss: 0.41009 | val_0_f1: 0.63584 | val_0_gini: 0.69028 |  0:00:04s\n",
      "epoch 18 | loss: 0.5132  | val_0_f1: 0.61206 | val_0_gini: 0.6726  |  0:00:04s\n",
      "epoch 19 | loss: 0.49592 | val_0_f1: 0.634   | val_0_gini: 0.66609 |  0:00:04s\n",
      "epoch 20 | loss: 0.42347 | val_0_f1: 0.60746 | val_0_gini: 0.65979 |  0:00:05s\n",
      "epoch 21 | loss: 0.46025 | val_0_f1: 0.58141 | val_0_gini: 0.65843 |  0:00:05s\n",
      "epoch 22 | loss: 0.45859 | val_0_f1: 0.61092 | val_0_gini: 0.66472 |  0:00:05s\n",
      "epoch 23 | loss: 0.41943 | val_0_f1: 0.62404 | val_0_gini: 0.65185 |  0:00:05s\n",
      "epoch 24 | loss: 0.46264 | val_0_f1: 0.6434  | val_0_gini: 0.66526 |  0:00:06s\n",
      "epoch 25 | loss: 0.43008 | val_0_f1: 0.62787 | val_0_gini: 0.66745 |  0:00:06s\n",
      "epoch 26 | loss: 0.40573 | val_0_f1: 0.60698 | val_0_gini: 0.64651 |  0:00:06s\n",
      "epoch 27 | loss: 0.41993 | val_0_f1: 0.59207 | val_0_gini: 0.6177  |  0:00:06s\n",
      "\n",
      "Early stopping occured at epoch 27 with best_epoch = 17 and best_val_0_gini = 0.69028\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "preds = []\n",
    "cv_preds = []\n",
    "for train_index, test_index in skf.split(X_t, y):\n",
    "    xtrain = X_t[train_index]\n",
    "    ytrain = y[train_index]\n",
    "    xval = X_t[test_index]\n",
    "    yval = y[test_index]\n",
    "    clf = TabNetClassifier(seed=42) \n",
    "    clf.fit(\n",
    "        xtrain, ytrain, eval_set=[(xval, yval)], weights=1,\n",
    "        eval_metric=[F1, Gini]\n",
    "    )\n",
    "    cv_preds.append(clf.predict_proba(X_t))\n",
    "    preds.append(clf.predict_proba(X_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276470588235294"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install --upgrade pytorch_tabnet\n",
    "np.mean(np.stack(cv_preds).mean(0).argmax(1)+1==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['NSP'] = np.stack(preds).mean(0).argmax(1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"prediction_tabnet.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
